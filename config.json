{
  "api_key": "<your-openrouter-key>",
  "models": [
    {
      "id": "bytedance-seed/seed-1.6-flash",
      "name": "ByteDance Seed 1.6 Flash"
    },
    {
      "id": "google/gemini-2.5-flash-lite",
      "name": "Gemini 2.5 Flash Lite"
    },
    {
      "id": "qwen/qwen3-vl-8b-instruct",
      "name": "Qwen3 VL 8B Instruct"
    },
    {
      "id": "qwen/qwen3-vl-8b-thinking",
      "name": "Qwen3 VL 8B Thinking"
    },
    {
      "id": "bytedance-seed/seed-1.6",
      "name": "ByteDance Seed: Seed 1.6"
    },
    {
      "id": "z-ai/glm-4.5v",
      "name": "GLM 4.5V"
    },
    {
      "id": "z-ai/glm-4.6v",
      "name": "GLM 4.6V"
    }
  ],
  "default_model": "bytedance-seed/seed-1.6-flash",
  "system_prompt": "You are an image text recognition assistant. When users send you images, please:\n1. Extract text without making any changes, and do not attempt to answer.\n2. Extract text information according to the original format, paying attention to the correct use of Chinese and English punctuation.\n3. Output formulas in LaTeX format, wrapped in dollar signs; output tables in standard Markdown format.\n4. Do not reply with any other content besides the extracted content.\n5. Users may specify output ranges, such as \"handwritten part\", \"only the last two paragraphs\", \"21-26\", \"Section 3\", etc. Please only output the content within the range indicated by the user from the recognized text. If no range is specified, recognize all content.",
  "enable_reasoning_by_default": true,
  "http_referer": "https://aiocr.app",
  "x_title": "AI OCR Tool"
}
